{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"notes/Reddit%E7%88%AC%E8%99%AB%E6%89%80%E9%81%87%E9%97%AE%E9%A2%98%E8%AF%A6%E8%A7%A3/","text":"Reddit\u722c\u866b\u7b14\u8bb0 \u00b6 Reddit is a network of communities where people can dive into their interests, hobbies and passions. There\u2019s a community for whatever you\u2019re interested in on Reddit . \u7b80\u5355\u6765\u8bb2\uff0cReddit\u5c31\u662f\u5728\u7279\u5b9a\u5b50\u4e3b\u9898\u4e0b\u7528\u6237\u81ea\u52a8\u53d1\u6398\u5185\u5bb9\u548c\u5206\u4eab\u7684\u8ba8\u8bba\u793e\u533a\uff0c\u5176\u4e2d\u5305\u542b\u5e16\u5b50\u3001\u8bc4\u8bba\u3001\u6295\u7968\u3001\u70b9\u8d5e\u3001\u5206\u4eab\u7b49\u64cd\u4f5c\uff0c\u5176\u64cd\u4f5c\u81ea\u7531\u5ea6\u548c\u4ea4\u4e92\u6027\u975e\u5e38\u9002\u5408\u5e7f\u5927\u7528\u6237\u521b\u9020\u4ef7\u503c\u3002 Reddit\u5bf9\u4e8e\u6570\u636e\u6316\u6398\u5de5\u4f5c\u8005\u975e\u5e38\u53cb\u597d\u3002\u5176\u4e00\u5728\u4e8e\uff0c\u76ee\u524d\u5df2\u6709\u975e\u5e38\u591a\u7684Reddit\u516c\u5f00\u6570\u636e\u96c6\u53ef\u4ee5\u65b9\u4fbf\u83b7\u53d6\uff0c\u5982REDDITBINARY\u3001REDDITMULTI5K\u7b49\u6570\u636e\u96c6\u88ab\u5e7f\u6cdb\u7528\u4e8e\u9876\u4f1a\u4e2d\u7cfb\u5217\u6a21\u578b\u7684\u8bad\u7ec3\u3002\u53e6\u5916\uff0cReddit\u7f51\u7ad9\u4e5f\u63d0\u4f9b\u4e86\u9650\u5236\u8f83\u5c11\u7684API\uff0c\u53ef\u4ee5\u7b80\u5355\u4e0a\u624b\u83b7\u53d6\u5230\u79f0\u5fc3\u5982\u610f\u7684\u4e00\u624b\u7814\u7a76\u6570\u636e\u3002\u56e0\u6b64\uff0c\u7814\u7a76Reddit\u6570\u636e\u96c6\u5982\u4f55\u83b7\u53d6\u5bf9\u4e8e\u5f80\u540e\u7684\u7814\u7a76\u5de5\u4f5c\u662f\u5341\u5206\u5fc5\u8981\u7684\u3002 Reddit\u722c\u866b\u65b9\u5f0f \u00b6 Reddit API \u00b6 \u6709\u7528\u7684\u94fe\u63a5\u5730\u5740 \u5b98\u65b9 api \u8bf4\u660e\u6587\u6863 \u5b98\u65b9 api \u4f7f\u7528\u89c4\u8303 reddit \u6388\u6743\u8bf4\u660e reddit app \u5217\u8868\u5730\u5740 praw \u6587\u6863 python \u91c7\u96c6 reddit \u4f8b\u5b50 \u5177\u4f53\u64cd\u4f5c\u6b65\u9aa4\uff1a \u6ce8\u518cReddit\u8d26\u53f7 \u7533\u8bf7Reddit API \u9996\u5148\u5728 Reddit app \u4ee5Script for personal use\u8eab\u4efd\u586b\u5199name, description, redirect url\uff0c\u7136\u540ecreate app\u5f97\u5230\u4ee5\u4e0b\u7684\u4fe1\u606f\uff1a client_id : The client ID is at least a 14-character string listed just under \u201cpersonal use script\u201d for the desired developed application client_secret : The client secret is at least a 27-character string listed adjacent to secret for the application. password : The password for the Reddit account used to register the application. username : The username of the Reddit account used to register the application. \u4fe1\u606f\u8be6\u7ec6\u4ecb\u7ecd\u8bf7\u770b\uff1a Authenticating via OAuth \u2014 PRAW 7.6.1.dev0 documentation \u5229\u7528\u4ee5\u4e0a\u4fe1\u606f\u5f00\u59cb\u586b\u5199\u4ee3\u7801 # coding: UTF-8 #!/use/bin/env python3 import praw import pandas as pd import datetime as dt reddit = praw.Reddit( client_id='your-clientID', client_secret='your secret', user_agent='your_platform:dev_tmp:v0.1 (by /u/dev_tmp)', # redirect_uri='http://localhost:8080' username='dev_tmp', password='HGFhgf123' ) # print(reddit.auth.url([\"identity\"], \"...\", \"permanent\")) print(reddit.user.me()) # all \u662f<class 'praw.models.reddit.subreddit.Subreddit'>\u7c7b\u578b, # \u5177\u4f53\u4f7f\u7528\u89c1\uff1ahttps://praw.readthedocs.io/en/latest/code_overview/models/subreddit.html all = reddit.subreddit(\"all\") print(type(all)) # submission \u7684\u7c7b\u578b\u662f<class 'praw.models.reddit.submission.Submission'>\uff0c # \u5177\u4f53\u5c5e\u6027\u5217\u8868\u89c1\uff1ahttps://praw.readthedocs.io/en/latest/code_overview/models/submission.html messages = { \"id\": [], \"url\": [], \"title\": [], \"score\": [], \"comms_num\": [], \"body\": [], \"created\": [] } for submission in all.search(\"tiktok\", limit=5): messages[\"id\"].append(submission.id) messages[\"url\"].append(submission.url) messages[\"title\"].append(submission.title) messages[\"score\"].append(submission.score) messages[\"comms_num\"].append(submission.num_comments) messages[\"body\"].append(submission.selftext) messages[\"created\"].append(submission.created) # search \u7ed3\u679c\u7c7b\u578b\u662f<class 'praw.models.listing.generator.ListingGenerator'> # praw \u4e2d\u7684\u5176\u4ed6\u7c7b\u578b\u6587\u6863\u4e3a\uff1a https://praw.readthedocs.io/en/latest/code_overview/other.html # res = all.search(\"tiktok\") # print(type(res)) data = pd.DataFrame(messages) data.to_csv('data.csv', index=False) \u8fd9\u6837\u5c31\u80fd\u83b7\u5f97\u4f60\u60f3\u8981\u7684\u6570\u636e\u4e86 reddit API\u6301\u7eed\u5f00\u53d1| \u8fd9\u90e8\u5206\u53ef\u4ee5\u8be6\u89c1Reddit\u7ed9\u51fa\u7684\u5b98\u65b9\u6587\u6863\uff0c\u6309\u7167\u6587\u6863\u5373\u53ef\u5f97\u5230\u76f8\u5e94\u7684\u6570\u636e\u3002 \u4f46\u662f\u53ef\u80fd\u4f1a\u5b58\u5728\u4ee5\u4e0b\u7684\u95ee\u9898\uff0c\u6211\u5df2\u7ecf\u7ed9\u51fa\u4e86\u89e3\u51b3\u65b9\u6cd5\u5982\u4e0b\u3002 \u95ee\u9898\uff1a\u76ee\u524dReddit \u53ea\u80fd\u79d1\u5b66\u8bbf\u95ee\u3002\u5982\u679c\u6309\u7167\u6b63\u5e38\u7684\u722c\u866b\u65b9\u5f0f\u6765\u83b7\u53d6\u7f51\u7ad9\u6570\u636e\u4f1a\u9047\u5230 prawcore.exceptions.RequestException: error with request HTTPSConnectionPool(host=\u2019 www.reddit.com \u2019, port=443 ): Max retries exceeded with url: /api/v1/access_token (Caused by ProxyError(\u2018Cannot connect to proxy.\u2019, OSError(0, \u2018Error\u2019)))>) ***\u89e3\u51b3: \u76f8\u5173\u89e3\u51b3\u53c2\u8003 # HTTPSConnectionPool(host=\u2019xxxxx\u2019, port=443): Max retries exceeded with url:xxxxxxxx (Caused by Ne\u2026 , python\u722c\u866b\u4e4brequests.exceptions.ProxyError: HTTPSConnectionPool(host=\u2019www.xxxx.com\u2019, port=443): Max retries exceeded with url: / (Caused by ProxyError(\u2018Cannot connect to proxy.\u2019, timeout(\u2018_ssl.c:1108: Th - Eeyhan - \u535a\u5ba2\u56ed (cnblogs.com) - \u4f7f\u7528VPN\u79d1\u5b66\u8bbf\u95ee\u89e3\u51b3error with request HTTPSConnectionPool\u3002l[Clash for Windows](../Clash%20for%20Windows \"Clash for Windows\") \u4ec5\u652f\u6301\u6d4f\u89c8\u5668\u7f51\u9875\uff0c\u5176\u4ed6\u7a0b\u5e8f\u7c7b\u8f6f\u4ef6\u65e0\u6cd5\u4f7f\u7528\u5b83\u8fdb\u884c\u79d1\u5b66\u4e0a\u7f51\u3002\u4f46\u662f\u5b83\u63d0\u4f9b\u4e86\u4e00\u4e2a\u975e\u5e38\u4fbf\u6377\u7684\u5de5\u5177TUN Mode\uff0c\u53ef\u4ee5\u4f7f\u6240\u6709\u7684\u7a0b\u5e8f\u90fd\u7ecf\u8fc7Proxy\u8fdb\u884c\u79d1\u5b66\u8bbf\u95ee\uff0c\u8fd9\u6837\u5c31\u80fd\u89e3\u51b3ProxyError\u7b49\u95ee\u9898\u3002\u53e6\u5916\uff0c\u6700\u597d\u9009\u53d6GLobal\u4e0b\u7684\u7f8e\u56fd\u670d\u52a1\u5668\u4f1a\u66f4\u52a0\u7a33\u5b9a\u3002\u5982\u679c\u60f3\u66f4\u52a0\u9ad8\u6548\u7a33\u5b9a\u722c\u53d6\u5927\u91cfReddit\u6570\u636e\uff0c\u53ef\u4ee5\u9009\u62e9\u5c06[\u7a0b\u5e8f\u90e8\u7f72\u56fd\u5916\u5916\u7f51\u670d\u52a1\u5668\u722c\u53d6](../%E7%A8%8B%E5%BA%8F%E9%83%A8%E7%BD%B2%E5%9B%BD%E5%A4%96%E5%A4%96%E7%BD%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%88%AC%E5%8F%96 \"\u7a0b\u5e8f\u90e8\u7f72\u56fd\u5916\u5916\u7f51\u670d\u52a1\u5668\u722c\u53d6\")\u3002 - \u5173\u95ed\u7cfb\u7edf\u4ee3\u7406ProxyError\u3002\u7cfb\u7edf\u4ee3\u7406\u4ecd\u7136\u4f1a\u5bfc\u81f4\u51fa\u73b0\u4e0a\u8ff0\u9519\u8bef\u3002 ![Pasted image 20220520174235.png](../assets/img/Pasted%20image%2020220520174235.png \"Pasted image 20220520174235.png\") Reddit\u7f51\u7ad9API\u722c\u866b\u793a\u4f8b\u53ef\u4ee5\u53c2\u89c1\uff1a (36\u6761\u6d88\u606f) Reddit\u7f51\u7ad9\u83b7\u8d5e\u6700\u9ad8\u6587\u7ae0/\u8bc4\u8bba\u7684\u722c\u53d6_\u5c0f\u4e2b\u5934\u3044\u7684\u535a\u5ba2-CSDN\u535a\u5ba2 \u5982\u4f55\u91c7\u96c6reddit - hgf doing - OSCHINA - \u4e2d\u6587\u5f00\u6e90\u6280\u672f\u4ea4\u6d41\u793e\u533a Scrapy \u722c\u866b \u00b6 Scrapy\u722c\u866b\u7684\u7b80\u5355\u4ecb\u7ecd\u53ef\u4ee5\u53c2\u89c1\uff1a 1. Scrapy\u6846\u67b6\u4ecb\u7ecd\u4e0e\u5b89\u88c5 \u00b7 GitBook (csdn.net) Scrapy\u722c\u866b\u6846\u67b6\u6559\u7a0b\uff08\u4e00\uff09\u2013 Scrapy\u5165\u95e8 - \u77e5\u4e4e (zhihu.com) (36\u6761\u6d88\u606f) Scrapy\u722c\u866b\u5165\u95e8\u6559\u7a0b\u5341\u4e09 Settings\uff08\u8bbe\u7f6e\uff09___\u9759\u7985__\u7684\u535a\u5ba2-CSDN\u535a\u5ba2 \u521b\u5efa\u9879\u76ee scrapy startproject reddit \u5c31\u4f1a\u5f97\u5230\u8fd9\u6837\u7684\u6587\u4ef6\u5939 reddit/ scrapy.cfg reddit/ __init__.py items.py pipelines.py settings.py spiders/ __init__.py ... \u8fd9\u4e9b\u6587\u4ef6\u5206\u522b\u662f: scrapy.cfg: \u9879\u76ee\u7684\u914d\u7f6e\u6587\u4ef6\u3002 reddit/: \u8be5\u9879\u76ee\u7684python\u6a21\u5757\u3002\u4e4b\u540e\u60a8\u5c06\u5728\u6b64\u52a0\u5165\u4ee3\u7801\u3002 reddit/items.py: \u9879\u76ee\u4e2d\u7684item\u6587\u4ef6\u3002 reddit/pipelines.py: \u9879\u76ee\u4e2d\u7684pipelines\u6587\u4ef6\u3002 reddit/settings.py: \u9879\u76ee\u7684\u8bbe\u7f6e\u6587\u4ef6\u3002 reddit/spiders/: \u653e\u7f6espider\u4ee3\u7801\u7684\u76ee\u5f55\u3002 \u5728reddit/spiders\u76ee\u5f55\u4e0b\u521b\u5efareddit.py\u6587\u4ef6 scrapy genspider reddit reddit.com \u542f\u52a8\u722c\u866b scrapy crawl reddit \u8fd9\u6837\u5c31\u53ef\u4ee5\u722c\u53d6reddit.com\u4e0a\u7684\u5b50\u793e\u533a\u7684\u6570\u636e\u5566\u3002 Reddit\u7f51\u7ad9Scrapy\u722c\u866b\u793a\u4f8b\u53ef\u4ee5\u53c2\u89c1\uff1a Article-for-Datartisan/\u57fa\u4e8eScrapy\u7684Reddit\u722c\u53d6\u4e0e\u5206\u6790.md at master \u00b7 fibears/Article-for-Datartisan (github.com) Scraping Reddit - DataScienceCentral.com StrikingLoo/kitten-getter: A Spider that crawls reddit.com/r/cats (github.com) \u4f2a\u88c5\u8bf7\u6c42\u5934\u722c\u866b \u00b6 request\u7f51\u9875\u8fd4\u56deresponse import requests import csv import time from bs4 import BeautifulSoup4 url = \"https://old.reddit.com/r/datascience/\" # Headers to mimic a browser visit headers = {'User-Agent': 'Mozilla/5.0'} # Returns a requests.models.Response object page = requests.get(url, headers=headers) \u9700\u8981\u4e3b\u8981\u662f\u8fd9\u6837\u7684\u65b9\u5f0f\u722c\u866b\u4f1a\u5bfc\u81f4UA\u548cIP\u88ab\u5c01\uff0c\u56e0\u6b64\uff0c\u6211\u4eec\u9700\u8981\u5efa\u7acbRandom UA\u548cIP\u6c60\u6765\u52a8\u6001\u7ba1\u7406\u722c\u866b\u8fdb\u7a0b\u7684\u4f2a\u88c5\uff0c\u5177\u4f53\u7684\u64cd\u4f5c\u53ef\u4ee5\u8be6\u89c1\uff1a (36\u6761\u6d88\u606f) \u516b\u3001python\u722c\u866b\u4f2a\u88c5 [\u514d\u8d39\u4f2a\u88c5ip\u4f2a\u88c5\u8bf7\u6c42\u5934]_\u8881\u516d\u52a0.\u7684\u535a\u5ba2-CSDN\u535a\u5ba2_python\u4f2a\u88c5ip Reddit\u7f51\u7ad9\u4f2a\u88c5\u8bf7\u6c42\u5934\u722c\u866b\u793a\u4f8b\u53ef\u4ee5\u53c2\u89c1\uff1a \u4f7f\u7528Python\u548cBeautifulSoup 4\u6293\u53d6Reddit - H5W3 \u603b\u7ed3 \u00b6 \u81f3\u6b64\uff0c\u5173\u4e8eReddit\u7f51\u7ad9\u7684\u722c\u866b\u65b9\u5f0f\u5df2\u7ecf\u4ecb\u7ecd\u5b8c\u6bd5\uff0c\u540e\u7eed\u7684\u4f7f\u7528\u5c06\u7ee7\u7eed\u66f4\u65b0\u3002","title":"Reddit\u722c\u866b\u7b14\u8bb0"},{"location":"notes/Reddit%E7%88%AC%E8%99%AB%E6%89%80%E9%81%87%E9%97%AE%E9%A2%98%E8%AF%A6%E8%A7%A3/#reddit","text":"Reddit is a network of communities where people can dive into their interests, hobbies and passions. There\u2019s a community for whatever you\u2019re interested in on Reddit . \u7b80\u5355\u6765\u8bb2\uff0cReddit\u5c31\u662f\u5728\u7279\u5b9a\u5b50\u4e3b\u9898\u4e0b\u7528\u6237\u81ea\u52a8\u53d1\u6398\u5185\u5bb9\u548c\u5206\u4eab\u7684\u8ba8\u8bba\u793e\u533a\uff0c\u5176\u4e2d\u5305\u542b\u5e16\u5b50\u3001\u8bc4\u8bba\u3001\u6295\u7968\u3001\u70b9\u8d5e\u3001\u5206\u4eab\u7b49\u64cd\u4f5c\uff0c\u5176\u64cd\u4f5c\u81ea\u7531\u5ea6\u548c\u4ea4\u4e92\u6027\u975e\u5e38\u9002\u5408\u5e7f\u5927\u7528\u6237\u521b\u9020\u4ef7\u503c\u3002 Reddit\u5bf9\u4e8e\u6570\u636e\u6316\u6398\u5de5\u4f5c\u8005\u975e\u5e38\u53cb\u597d\u3002\u5176\u4e00\u5728\u4e8e\uff0c\u76ee\u524d\u5df2\u6709\u975e\u5e38\u591a\u7684Reddit\u516c\u5f00\u6570\u636e\u96c6\u53ef\u4ee5\u65b9\u4fbf\u83b7\u53d6\uff0c\u5982REDDITBINARY\u3001REDDITMULTI5K\u7b49\u6570\u636e\u96c6\u88ab\u5e7f\u6cdb\u7528\u4e8e\u9876\u4f1a\u4e2d\u7cfb\u5217\u6a21\u578b\u7684\u8bad\u7ec3\u3002\u53e6\u5916\uff0cReddit\u7f51\u7ad9\u4e5f\u63d0\u4f9b\u4e86\u9650\u5236\u8f83\u5c11\u7684API\uff0c\u53ef\u4ee5\u7b80\u5355\u4e0a\u624b\u83b7\u53d6\u5230\u79f0\u5fc3\u5982\u610f\u7684\u4e00\u624b\u7814\u7a76\u6570\u636e\u3002\u56e0\u6b64\uff0c\u7814\u7a76Reddit\u6570\u636e\u96c6\u5982\u4f55\u83b7\u53d6\u5bf9\u4e8e\u5f80\u540e\u7684\u7814\u7a76\u5de5\u4f5c\u662f\u5341\u5206\u5fc5\u8981\u7684\u3002","title":"Reddit\u722c\u866b\u7b14\u8bb0"},{"location":"notes/Reddit%E7%88%AC%E8%99%AB%E6%89%80%E9%81%87%E9%97%AE%E9%A2%98%E8%AF%A6%E8%A7%A3/#reddit_1","text":"","title":"Reddit\u722c\u866b\u65b9\u5f0f"},{"location":"notes/Reddit%E7%88%AC%E8%99%AB%E6%89%80%E9%81%87%E9%97%AE%E9%A2%98%E8%AF%A6%E8%A7%A3/#reddit-api","text":"\u6709\u7528\u7684\u94fe\u63a5\u5730\u5740 \u5b98\u65b9 api \u8bf4\u660e\u6587\u6863 \u5b98\u65b9 api \u4f7f\u7528\u89c4\u8303 reddit \u6388\u6743\u8bf4\u660e reddit app \u5217\u8868\u5730\u5740 praw \u6587\u6863 python \u91c7\u96c6 reddit \u4f8b\u5b50 \u5177\u4f53\u64cd\u4f5c\u6b65\u9aa4\uff1a \u6ce8\u518cReddit\u8d26\u53f7 \u7533\u8bf7Reddit API \u9996\u5148\u5728 Reddit app \u4ee5Script for personal use\u8eab\u4efd\u586b\u5199name, description, redirect url\uff0c\u7136\u540ecreate app\u5f97\u5230\u4ee5\u4e0b\u7684\u4fe1\u606f\uff1a client_id : The client ID is at least a 14-character string listed just under \u201cpersonal use script\u201d for the desired developed application client_secret : The client secret is at least a 27-character string listed adjacent to secret for the application. password : The password for the Reddit account used to register the application. username : The username of the Reddit account used to register the application. \u4fe1\u606f\u8be6\u7ec6\u4ecb\u7ecd\u8bf7\u770b\uff1a Authenticating via OAuth \u2014 PRAW 7.6.1.dev0 documentation \u5229\u7528\u4ee5\u4e0a\u4fe1\u606f\u5f00\u59cb\u586b\u5199\u4ee3\u7801 # coding: UTF-8 #!/use/bin/env python3 import praw import pandas as pd import datetime as dt reddit = praw.Reddit( client_id='your-clientID', client_secret='your secret', user_agent='your_platform:dev_tmp:v0.1 (by /u/dev_tmp)', # redirect_uri='http://localhost:8080' username='dev_tmp', password='HGFhgf123' ) # print(reddit.auth.url([\"identity\"], \"...\", \"permanent\")) print(reddit.user.me()) # all \u662f<class 'praw.models.reddit.subreddit.Subreddit'>\u7c7b\u578b, # \u5177\u4f53\u4f7f\u7528\u89c1\uff1ahttps://praw.readthedocs.io/en/latest/code_overview/models/subreddit.html all = reddit.subreddit(\"all\") print(type(all)) # submission \u7684\u7c7b\u578b\u662f<class 'praw.models.reddit.submission.Submission'>\uff0c # \u5177\u4f53\u5c5e\u6027\u5217\u8868\u89c1\uff1ahttps://praw.readthedocs.io/en/latest/code_overview/models/submission.html messages = { \"id\": [], \"url\": [], \"title\": [], \"score\": [], \"comms_num\": [], \"body\": [], \"created\": [] } for submission in all.search(\"tiktok\", limit=5): messages[\"id\"].append(submission.id) messages[\"url\"].append(submission.url) messages[\"title\"].append(submission.title) messages[\"score\"].append(submission.score) messages[\"comms_num\"].append(submission.num_comments) messages[\"body\"].append(submission.selftext) messages[\"created\"].append(submission.created) # search \u7ed3\u679c\u7c7b\u578b\u662f<class 'praw.models.listing.generator.ListingGenerator'> # praw \u4e2d\u7684\u5176\u4ed6\u7c7b\u578b\u6587\u6863\u4e3a\uff1a https://praw.readthedocs.io/en/latest/code_overview/other.html # res = all.search(\"tiktok\") # print(type(res)) data = pd.DataFrame(messages) data.to_csv('data.csv', index=False) \u8fd9\u6837\u5c31\u80fd\u83b7\u5f97\u4f60\u60f3\u8981\u7684\u6570\u636e\u4e86 reddit API\u6301\u7eed\u5f00\u53d1| \u8fd9\u90e8\u5206\u53ef\u4ee5\u8be6\u89c1Reddit\u7ed9\u51fa\u7684\u5b98\u65b9\u6587\u6863\uff0c\u6309\u7167\u6587\u6863\u5373\u53ef\u5f97\u5230\u76f8\u5e94\u7684\u6570\u636e\u3002 \u4f46\u662f\u53ef\u80fd\u4f1a\u5b58\u5728\u4ee5\u4e0b\u7684\u95ee\u9898\uff0c\u6211\u5df2\u7ecf\u7ed9\u51fa\u4e86\u89e3\u51b3\u65b9\u6cd5\u5982\u4e0b\u3002 \u95ee\u9898\uff1a\u76ee\u524dReddit \u53ea\u80fd\u79d1\u5b66\u8bbf\u95ee\u3002\u5982\u679c\u6309\u7167\u6b63\u5e38\u7684\u722c\u866b\u65b9\u5f0f\u6765\u83b7\u53d6\u7f51\u7ad9\u6570\u636e\u4f1a\u9047\u5230 prawcore.exceptions.RequestException: error with request HTTPSConnectionPool(host=\u2019 www.reddit.com \u2019, port=443 ): Max retries exceeded with url: /api/v1/access_token (Caused by ProxyError(\u2018Cannot connect to proxy.\u2019, OSError(0, \u2018Error\u2019)))>) ***\u89e3\u51b3: \u76f8\u5173\u89e3\u51b3\u53c2\u8003 # HTTPSConnectionPool(host=\u2019xxxxx\u2019, port=443): Max retries exceeded with url:xxxxxxxx (Caused by Ne\u2026 , python\u722c\u866b\u4e4brequests.exceptions.ProxyError: HTTPSConnectionPool(host=\u2019www.xxxx.com\u2019, port=443): Max retries exceeded with url: / (Caused by ProxyError(\u2018Cannot connect to proxy.\u2019, timeout(\u2018_ssl.c:1108: Th - Eeyhan - \u535a\u5ba2\u56ed (cnblogs.com) - \u4f7f\u7528VPN\u79d1\u5b66\u8bbf\u95ee\u89e3\u51b3error with request HTTPSConnectionPool\u3002l[Clash for Windows](../Clash%20for%20Windows \"Clash for Windows\") \u4ec5\u652f\u6301\u6d4f\u89c8\u5668\u7f51\u9875\uff0c\u5176\u4ed6\u7a0b\u5e8f\u7c7b\u8f6f\u4ef6\u65e0\u6cd5\u4f7f\u7528\u5b83\u8fdb\u884c\u79d1\u5b66\u4e0a\u7f51\u3002\u4f46\u662f\u5b83\u63d0\u4f9b\u4e86\u4e00\u4e2a\u975e\u5e38\u4fbf\u6377\u7684\u5de5\u5177TUN Mode\uff0c\u53ef\u4ee5\u4f7f\u6240\u6709\u7684\u7a0b\u5e8f\u90fd\u7ecf\u8fc7Proxy\u8fdb\u884c\u79d1\u5b66\u8bbf\u95ee\uff0c\u8fd9\u6837\u5c31\u80fd\u89e3\u51b3ProxyError\u7b49\u95ee\u9898\u3002\u53e6\u5916\uff0c\u6700\u597d\u9009\u53d6GLobal\u4e0b\u7684\u7f8e\u56fd\u670d\u52a1\u5668\u4f1a\u66f4\u52a0\u7a33\u5b9a\u3002\u5982\u679c\u60f3\u66f4\u52a0\u9ad8\u6548\u7a33\u5b9a\u722c\u53d6\u5927\u91cfReddit\u6570\u636e\uff0c\u53ef\u4ee5\u9009\u62e9\u5c06[\u7a0b\u5e8f\u90e8\u7f72\u56fd\u5916\u5916\u7f51\u670d\u52a1\u5668\u722c\u53d6](../%E7%A8%8B%E5%BA%8F%E9%83%A8%E7%BD%B2%E5%9B%BD%E5%A4%96%E5%A4%96%E7%BD%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%88%AC%E5%8F%96 \"\u7a0b\u5e8f\u90e8\u7f72\u56fd\u5916\u5916\u7f51\u670d\u52a1\u5668\u722c\u53d6\")\u3002 - \u5173\u95ed\u7cfb\u7edf\u4ee3\u7406ProxyError\u3002\u7cfb\u7edf\u4ee3\u7406\u4ecd\u7136\u4f1a\u5bfc\u81f4\u51fa\u73b0\u4e0a\u8ff0\u9519\u8bef\u3002 ![Pasted image 20220520174235.png](../assets/img/Pasted%20image%2020220520174235.png \"Pasted image 20220520174235.png\") Reddit\u7f51\u7ad9API\u722c\u866b\u793a\u4f8b\u53ef\u4ee5\u53c2\u89c1\uff1a (36\u6761\u6d88\u606f) Reddit\u7f51\u7ad9\u83b7\u8d5e\u6700\u9ad8\u6587\u7ae0/\u8bc4\u8bba\u7684\u722c\u53d6_\u5c0f\u4e2b\u5934\u3044\u7684\u535a\u5ba2-CSDN\u535a\u5ba2 \u5982\u4f55\u91c7\u96c6reddit - hgf doing - OSCHINA - \u4e2d\u6587\u5f00\u6e90\u6280\u672f\u4ea4\u6d41\u793e\u533a","title":"Reddit API"},{"location":"notes/Reddit%E7%88%AC%E8%99%AB%E6%89%80%E9%81%87%E9%97%AE%E9%A2%98%E8%AF%A6%E8%A7%A3/#scrapy","text":"Scrapy\u722c\u866b\u7684\u7b80\u5355\u4ecb\u7ecd\u53ef\u4ee5\u53c2\u89c1\uff1a 1. Scrapy\u6846\u67b6\u4ecb\u7ecd\u4e0e\u5b89\u88c5 \u00b7 GitBook (csdn.net) Scrapy\u722c\u866b\u6846\u67b6\u6559\u7a0b\uff08\u4e00\uff09\u2013 Scrapy\u5165\u95e8 - \u77e5\u4e4e (zhihu.com) (36\u6761\u6d88\u606f) Scrapy\u722c\u866b\u5165\u95e8\u6559\u7a0b\u5341\u4e09 Settings\uff08\u8bbe\u7f6e\uff09___\u9759\u7985__\u7684\u535a\u5ba2-CSDN\u535a\u5ba2 \u521b\u5efa\u9879\u76ee scrapy startproject reddit \u5c31\u4f1a\u5f97\u5230\u8fd9\u6837\u7684\u6587\u4ef6\u5939 reddit/ scrapy.cfg reddit/ __init__.py items.py pipelines.py settings.py spiders/ __init__.py ... \u8fd9\u4e9b\u6587\u4ef6\u5206\u522b\u662f: scrapy.cfg: \u9879\u76ee\u7684\u914d\u7f6e\u6587\u4ef6\u3002 reddit/: \u8be5\u9879\u76ee\u7684python\u6a21\u5757\u3002\u4e4b\u540e\u60a8\u5c06\u5728\u6b64\u52a0\u5165\u4ee3\u7801\u3002 reddit/items.py: \u9879\u76ee\u4e2d\u7684item\u6587\u4ef6\u3002 reddit/pipelines.py: \u9879\u76ee\u4e2d\u7684pipelines\u6587\u4ef6\u3002 reddit/settings.py: \u9879\u76ee\u7684\u8bbe\u7f6e\u6587\u4ef6\u3002 reddit/spiders/: \u653e\u7f6espider\u4ee3\u7801\u7684\u76ee\u5f55\u3002 \u5728reddit/spiders\u76ee\u5f55\u4e0b\u521b\u5efareddit.py\u6587\u4ef6 scrapy genspider reddit reddit.com \u542f\u52a8\u722c\u866b scrapy crawl reddit \u8fd9\u6837\u5c31\u53ef\u4ee5\u722c\u53d6reddit.com\u4e0a\u7684\u5b50\u793e\u533a\u7684\u6570\u636e\u5566\u3002 Reddit\u7f51\u7ad9Scrapy\u722c\u866b\u793a\u4f8b\u53ef\u4ee5\u53c2\u89c1\uff1a Article-for-Datartisan/\u57fa\u4e8eScrapy\u7684Reddit\u722c\u53d6\u4e0e\u5206\u6790.md at master \u00b7 fibears/Article-for-Datartisan (github.com) Scraping Reddit - DataScienceCentral.com StrikingLoo/kitten-getter: A Spider that crawls reddit.com/r/cats (github.com)","title":"Scrapy \u722c\u866b"},{"location":"notes/Reddit%E7%88%AC%E8%99%AB%E6%89%80%E9%81%87%E9%97%AE%E9%A2%98%E8%AF%A6%E8%A7%A3/#_1","text":"request\u7f51\u9875\u8fd4\u56deresponse import requests import csv import time from bs4 import BeautifulSoup4 url = \"https://old.reddit.com/r/datascience/\" # Headers to mimic a browser visit headers = {'User-Agent': 'Mozilla/5.0'} # Returns a requests.models.Response object page = requests.get(url, headers=headers) \u9700\u8981\u4e3b\u8981\u662f\u8fd9\u6837\u7684\u65b9\u5f0f\u722c\u866b\u4f1a\u5bfc\u81f4UA\u548cIP\u88ab\u5c01\uff0c\u56e0\u6b64\uff0c\u6211\u4eec\u9700\u8981\u5efa\u7acbRandom UA\u548cIP\u6c60\u6765\u52a8\u6001\u7ba1\u7406\u722c\u866b\u8fdb\u7a0b\u7684\u4f2a\u88c5\uff0c\u5177\u4f53\u7684\u64cd\u4f5c\u53ef\u4ee5\u8be6\u89c1\uff1a (36\u6761\u6d88\u606f) \u516b\u3001python\u722c\u866b\u4f2a\u88c5 [\u514d\u8d39\u4f2a\u88c5ip\u4f2a\u88c5\u8bf7\u6c42\u5934]_\u8881\u516d\u52a0.\u7684\u535a\u5ba2-CSDN\u535a\u5ba2_python\u4f2a\u88c5ip Reddit\u7f51\u7ad9\u4f2a\u88c5\u8bf7\u6c42\u5934\u722c\u866b\u793a\u4f8b\u53ef\u4ee5\u53c2\u89c1\uff1a \u4f7f\u7528Python\u548cBeautifulSoup 4\u6293\u53d6Reddit - H5W3","title":"\u4f2a\u88c5\u8bf7\u6c42\u5934\u722c\u866b"},{"location":"notes/Reddit%E7%88%AC%E8%99%AB%E6%89%80%E9%81%87%E9%97%AE%E9%A2%98%E8%AF%A6%E8%A7%A3/#_2","text":"\u81f3\u6b64\uff0c\u5173\u4e8eReddit\u7f51\u7ad9\u7684\u722c\u866b\u65b9\u5f0f\u5df2\u7ecf\u4ecb\u7ecd\u5b8c\u6bd5\uff0c\u540e\u7eed\u7684\u4f7f\u7528\u5c06\u7ee7\u7eed\u66f4\u65b0\u3002","title":"\u603b\u7ed3"}]}